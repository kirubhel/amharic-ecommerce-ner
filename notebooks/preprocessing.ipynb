{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# Amharic Text Preprocessing for E-commerce NER\n",
        "\n",
        "This notebook handles text cleaning, tokenization, and normalization for Amharic e-commerce data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "# For Amharic text processing\n",
        "# You may need to install: pip install ethiopic-calendar ethiopic-numbers\n",
        "import unicodedata\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## 1. Data Loading\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load raw Telegram data\n",
        "data_path = '../data/raw/'\n",
        "labeled_path = '../data/labeled/'\n",
        "\n",
        "# Load your raw data files here\n",
        "# raw_data = pd.read_csv(os.path.join(data_path, 'telegram_messages.csv'))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## 2. Text Cleaning Functions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def clean_amharic_text(text):\n",
        "    \"\"\"\n",
        "    Clean Amharic text by removing unwanted characters and normalizing\n",
        "    \"\"\"\n",
        "    if not isinstance(text, str):\n",
        "        return \"\"\n",
        "    \n",
        "    # Remove URLs\n",
        "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
        "    \n",
        "    # Remove email addresses\n",
        "    text = re.sub(r'\\S+@\\S+', '', text)\n",
        "    \n",
        "    # Remove extra whitespaces\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "    \n",
        "    # Normalize Unicode characters\n",
        "    text = unicodedata.normalize('NFC', text)\n",
        "    \n",
        "    return text.strip()\n",
        "\n",
        "def tokenize_amharic(text):\n",
        "    \"\"\"\n",
        "    Simple tokenization for Amharic text\n",
        "    \"\"\"\n",
        "    # Split by whitespace and punctuation\n",
        "    tokens = re.findall(r'[\\w]+|[።፣፤፥፦፧፨]', text)\n",
        "    return tokens\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## 3. Text Preprocessing Pipeline\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def preprocess_text(text):\n",
        "    \"\"\"\n",
        "    Complete preprocessing pipeline\n",
        "    \"\"\"\n",
        "    # Clean text\n",
        "    cleaned_text = clean_amharic_text(text)\n",
        "    \n",
        "    # Tokenize\n",
        "    tokens = tokenize_amharic(cleaned_text)\n",
        "    \n",
        "    return tokens\n",
        "\n",
        "# Example usage\n",
        "sample_text = \"ሰላም! ይህ ስልክ በ1000 ብር ይሸጣል። አዲስ አበባ ውስጥ ይገኛል።\"\n",
        "processed = preprocess_text(sample_text)\n",
        "print(\"Original:\", sample_text)\n",
        "print(\"Processed:\", processed)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def export_for_labeling(data, output_path):\n",
        "    \"\"\"\n",
        "    Export preprocessed data in a format suitable for manual labeling\n",
        "    \"\"\"\n",
        "    with open(output_path, 'w', encoding='utf-8') as f:\n",
        "        for text in data:\n",
        "            tokens = preprocess_text(text)\n",
        "            for token in tokens:\n",
        "                f.write(f\"{token}\\tO\\n\")  # Default to 'O' (Outside) label\n",
        "            f.write(\"\\n\")  # Empty line between sentences\n",
        "\n",
        "# Example export\n",
        "# export_for_labeling(raw_messages, '../data/labeled/unlabeled_data.conll')\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
